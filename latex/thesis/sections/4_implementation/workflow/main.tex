\begin{figure}[ht!]
    \centering
    \includegraphics[width=\linewidth]{images/project_plan.png}
    \caption{\label{fig::ProjectPlan} Complete VR and AR workflow for surgeons concept}
\end{figure}

"im rahmen eines größeren research projects in der MKG und VR Group"

This VR-application is in the context of a AR/VR-based surgical workflow as depicted in Figure \ref{fig::ProjectPlan}.
OMFS-Surgeons can plan procedures with familiar surgical instruments on realistic representations of patients.
Workflows can be imported and exported via a file in JSON-notation.
The system uses a mixture of natural hand gestures like grabbing objects with voice commands for navigation.
The patient can be freely scaled, rotated and moved for visualization purposes.
Patients can be resetted to the default position on the operating desk at any time.

\begin{enumerate}
    \setlength\itemsep{-0.5em}
    \item Acquisition of medical imaging (CT, DCT, MRT\ldots)
    \item Segmentation of volumetric data (DICOM) into 3D model data (STL, OBJ\ldots)
    \item Definition of project case in JSON-notation
    \item Import of project case
    \item Planning procedures in the context of project case
    \item Optional: Simulate procedure for learning and training purposes
    \item Save project case for use in AR or share with other surgeons
\end{enumerate}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=\linewidth]{images/implementation/workflow.png}
    \caption{\label{fig::ImplementationWorkflow}Step by Step workflow of processing project cases in VR}
\end{figure}

The workflow of the software is depicted in Figure \ref{fig::ImplementationWorkflow}.
Important to note is that the first two steps of the workflow are not part of this thesis, as they are provided in the scope of a previous research project by the department of oral and maxillofacial surgery in the university hospital of the RWTH Aachen and the VR Group of RWTH Aachen University.
Step one and two of the workflow are especially critical, as medical imaging techniques have their own advantages and disadvantages.
Also, while segmenting the medical imaging in step two, the decision about which tissue has which color and which tissue will be transparant is made.
Specific features of the software are dependant on decisions made in these two steps.

\input{sections/4_implementation/workflow/project_case.tex}

After setting up the project case, it can be loaded up at runtime inside of the VR-application.
Users can then view, add and edit existing procedures or create new ones.
If users wish to run through the planned procedure step by step, they can either navigate using the voice user interface or by enabling 'train mode' in which the user will be guided step by step through the procedure.
Here, users will be visually guided by the outlines of a surgical instrument to know where a procedure has to be performed.
Additionally, users will be guided via text inside of the application.
The text which is shown will be automatically generated with information about the current surgical instrument when performing a new procedure.
However, users are also free to edit the textual guidance manually via the JSON file in any way they see fit.
To confirm if the current procedure is carried out in the desired manner, voice feedback will notify the user if procedures are carried out correctly or if errors are being made.
The user can decide to save the current procedure for later use at any time of the process.